{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "data_path = \"data-001.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data-001.jsonl', 'validation.ipynb', '.gitignore', '.env', 'main.py', 'validation.py']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 4\n",
      "First example:\n",
      "[{'role': 'system', 'content': 'SciMLGPT is a chatbot trained to generate Julia code for Scientific machine learning problems.'}, {'role': 'user', 'content': 'Solve the ODE for SIR model'}, {'role': 'assistant', 'content': 'Here is the ode solver for the SIR model, ```using ComponentArrays, Lux, DiffEqFlux, OrdinaryDiffEq, Optimization, OptimizationOptimJL,OptimizationOptimisers, Random, Plots #u = [s(t), I(t), R(t)] function trueSirModel!(du, u, p, t) beta, gamma, N = p du[1] = -(beta * u[1] * u[2]) / N du[2] = ((beta * u[1] * u[2]) / N) - (gamma * u[2]) du[3] = gamma * u[2] end # Boundary conditions N = 1000 i0 = 1 r0 = 0 s0 = (N - i0 - r0) u0 = [s0, i0, r0] # constants beta = 0.3 gamma = 0.1 p = (beta, gamma, N)# time duration tspan = (0.0, 160.0) datasize = 160 tsteps = range(tspan[1], tspan[2]; length=datasize) # Solving the ODE solution trueOdeProblem = ODEProblem(trueSirModel!, u0, tspan, p) trueOdeData = Array(solve(trueOdeProblem, Tsit5(), saveat=tsteps))```'}]\n",
      "[{'role': 'system', 'content': 'SciMLGPT is a chatbot trained to generate Julia code for Scientific machine learning problems.'}, {'role': 'user', 'content': 'Implement the Neural ODE method for solving the SIR model '}, {'role': 'assistant', 'content': 'Here is the neural ode implementation for the SIR model, ```using ComponentArrays, Lux, DiffEqFlux, OrdinaryDiffEq, Optimization, OptimizationOptimJL, OptimizationOptimisers, Random, Plots #u = [s(t), I(t), R(t)] function trueSirModel!(du, u, p, t) beta, gamma, N = p du[1] = -(beta * u[1] * u[2]) / N du[2] = ((beta * u[1] * u[2]) / N) - (gamma * u[2]) du[3] = gamma * u[2] end # Boundary conditions N = 1000 i0 = 1 r0 = 0 s0 = (N - i0 - r0) u0 = [s0, i0, r0] # constants beta = 0.3 gamma = 0.1 p = (beta, gamma, N) # time duration tspan = (0.0, 160.0) datasize = 160 tsteps = range(tspan[1], tspan[2]; length=datasize) # Solving the ODE solution trueOdeProblem = ODEProblem(trueSirModel!, u0, tspan, p) trueOdeData = Array(solve(trueOdeProblem, Tsit5(), saveat=tsteps)) # Defining the Nueral Network rng = Random.default_rng() # After multiple iteraations, the layer with 3x150 fit the true data very well. sirNN = Lux.Chain(Lux.Dense(3, 150, tanh), Lux.Dense(150, 150, tanh), Lux.Dense(150, 3)) p, st = Lux.setup(rng, sirNN) sirNNOde = NeuralODE(sirNN, tspan, Tsit5(), saveat=tsteps) # prediciton function that is determined for every iteration function prediction(p) Array(sirNNOde(u0, p, st)[1]) end # Loss represents the difference between the original data and the predicted output function loss(p) pred = prediction(p) loss = sum(abs2, trueOdeData .- pred) return loss, pred end # A Callback function to plot the output of the true dat and predicted output for suspectible, infected and recvered data points callback = function (p, l, pred; doplot=true) println(l) if doplot plt = scatter(tsteps, trueOdeData[1, :]; label=\"true suspectible\") scatter!(plt, tsteps, pred[1, :]; label=\"prediction suspectible\") iplt = scatter(tsteps, trueOdeData[2, :]; label=\"true infected\") scatter!(iplt, tsteps, pred[2, :]; label=\"prediction infected\") rplt = scatter(tsteps, trueOdeData[3, :]; label=\"true recovered\") scatter!(rplt, tsteps, pred[3, :]; label=\"prediction recovered\") display(plot(plt, iplt, rplt)) end return false end # Defining optimization techniques pinit = ComponentArray(p) adtype = Optimization.AutoZygote() optimizeFunction = Optimization.OptimizationFunction((x, p) -> loss(x), adtype) # Defining the problem to be optimize neuralProblem = Optimization.OptimizationProblem(optimizeFunction, pinit) # NN solver that iterates over 3000 using ADAM optimizer result = Optimization.solve(neuralProblem, Optimisers.Adam(0.001); callback=callback, maxiters=3000)```'}]\n",
      "[{'role': 'system', 'content': 'SciMLGPT is a chatbot trained to generate Julia code for Scientific machine learning problems.'}, {'role': 'user', 'content': 'Implement the Neural ODE method for solving the SIR model '}, {'role': 'assistant', 'content': 'Here is the neural ode implementation for the SIR model, ```using ComponentArrays, Lux, DiffEqFlux, OrdinaryDiffEq, Optimization, OptimizationOptimJL, OptimizationOptimisers, Random, Plots #u = [s(t), I(t), R(t)] function trueSirModel!(du, u, p, t) beta, gamma, N = p du[1] = -(beta * u[1] * u[2]) / N du[2] = ((beta * u[1] * u[2]) / N) - (gamma * u[2]) du[3] = gamma * u[2] end # Boundary conditions N = 1000 i0 = 1 r0 = 0 s0 = (N - i0 - r0) u0 = [s0, i0, r0] # constants beta = 0.3 gamma = 0.1 p = (beta, gamma, N) # time duration tspan = (0.0, 160.0) datasize = 160 tsteps = range(tspan[1], tspan[2]; length=datasize) # Solving the ODE solution trueOdeProblem = ODEProblem(trueSirModel!, u0, tspan, p) trueOdeData = Array(solve(trueOdeProblem, Tsit5(), saveat=tsteps)) # Defining the Nueral Network rng = Random.default_rng() # After multiple iteraations, the layer with 3x150 fit the true data very well. sirNN = Lux.Chain(Lux.Dense(3, 150, tanh), Lux.Dense(150, 150, tanh), Lux.Dense(150, 3)) p, st = Lux.setup(rng, sirNN) sirNNOde = NeuralODE(sirNN, tspan, Tsit5(), saveat=tsteps) # prediciton function that is determined for every iteration function prediction(p) Array(sirNNOde(u0, p, st)[1]) end # Loss represents the difference between the original data and the predicted output function loss(p) pred = prediction(p) loss = sum(abs2, trueOdeData .- pred) return loss, pred end # A Callback function to plot the output of the true dat and predicted output for suspectible, infected and recvered data points callback = function (p, l, pred; doplot=true) println(l) if doplot plt = scatter(tsteps, trueOdeData[1, :]; label=\"true suspectible\") scatter!(plt, tsteps, pred[1, :]; label=\"prediction suspectible\") iplt = scatter(tsteps, trueOdeData[2, :]; label=\"true infected\") scatter!(iplt, tsteps, pred[2, :]; label=\"prediction infected\") rplt = scatter(tsteps, trueOdeData[3, :]; label=\"true recovered\") scatter!(rplt, tsteps, pred[3, :]; label=\"prediction recovered\") display(plot(plt, iplt, rplt)) end return false end # Defining optimization techniques pinit = ComponentArray(p) adtype = Optimization.AutoZygote() optimizeFunction = Optimization.OptimizationFunction((x, p) -> loss(x), adtype) # Defining the problem to be optimize neuralProblem = Optimization.OptimizationProblem(optimizeFunction, pinit) # NN solver that iterates over 3000 using ADAM optimizer result = Optimization.solve(neuralProblem, Optimisers.Adam(0.001); callback=callback, maxiters=3000)```'}]\n",
      "[{'role': 'system', 'content': 'SciMLGPT is a chatbot trained to generate Julia code for Scientific machine learning problems.'}, {'role': 'user', 'content': 'Similarly provide the UDE implementation for the Lotka Voltera eqautions '}, {'role': 'assistant', 'content': 'Here is the UDE implemenation for Lotka Voltera, ```using OrdinaryDiffEq, ModelingToolkit, SciMLSensitivity, DataDrivenSparse, Optimization, OptimizationOptimisers, OptimizationOptimJL, LinearAlgebra, Statistics, ComponentArrays, Lux, Zygote, Plots, StableRNGs; gr(); rng=StableRNG(1111); function lotka!(du,u,p,t) α,β,γ,δ=p; du[1]=α*u[1]-β*u[2]*u[1]; du[2]=γ*u[1]*u[2]-δ*u[2]; end; tspan=(0.0,15.0); u0=5.0f0*rand(rng,2); p_=[1.3,0.9,0.8,1.8]; prob=ODEProblem(lotka!,u0,tspan,p_); solution=solve(prob,Vern7(),abstol=1e-12,reltol=1e-12,saveat=0.25); X=Array(solution); t=solution.t; x̄=mean(X,dims=2); noise_magnitude=5e-3; Xₙ=X.+(noise_magnitude*x̄).*randn(rng,eltype(X),size(X)); plot(solution,alpha=0.75,color=:black,label=[\"True Data\" nothing]); scatter!(t,transpose(Xₙ),color=:red,label=[\"Noisy Data\" nothing]); rbf(x)=exp.(-(x.^2)); const U=Lux.Chain(Lux.Dense(2,5,rbf),Lux.Dense(5,5,rbf),Lux.Dense(5,5,rbf),Lux.Dense(5,2)); p,st=Lux.setup(rng,U); const _st=st; function ude_dynamics!(du,u,p,t,p_true) û=U(u,p,_st)[1]; du[1]=p_true[1]*u[1]+û[1]; du[2]=-p_true[4]*u[2]+û[2]; end; nn_dynamics!(du,u,p,t)=ude_dynamics!(du,u,p,t,p_); prob_nn=ODEProblem(nn_dynamics!,Xₙ[:,1],tspan,p); function predict(θ,X=Xₙ[:,1],T=t) _prob=remake(prob_nn,u0=X,tspan=(T[1],T[end]),p=θ); Array(solve(_prob,Vern7(),saveat=T,abstol=1e-6,reltol=1e-6,sensealg=QuadratureAdjoint(autojacvec=ReverseDiffVJP(true)))); end; function loss(θ) X̂=predict(θ); mean(abs2,Xₙ.-X̂); end; losses=Float64[]; callback=function(p,l) push!(losses,l); if length(losses)%50==0 println(\"Current loss after $(length(losses)) iterations: $(losses[end])\"); end; return false; end; adtype=Optimization.AutoZygote(); optf=Optimization.OptimizationFunction((x,p)->loss(x),adtype); optprob=Optimization.OptimizationProblem(optf,ComponentVector{Float64}(p)); res1=Optimization.solve(optprob,ADAM(),callback=callback,maxiters=5000); println(\"Training loss after $(length(losses)) iterations: $(losses[end])\"); optprob2=Optimization.OptimizationProblem(optf,res1.u); res2=Optimization.solve(optprob2,Optim.LBFGS(),callback=callback,maxiters=1000); println(\"Final training loss after $(length(losses)) iterations: $(losses[end])\"); p_trained=res2.u; pl_losses=plot(1:5000,losses[1:5000],yaxis=:log10,xaxis=:log10,xlabel=\"Iterations\",ylabel=\"Loss\",label=\"ADAM\",color=:blue); plot!(5001:length(losses),losses[5001:end],yaxis=:log10,xaxis=:log10,xlabel=\"Iterations\",ylabel=\"Loss\",label=\"BFGS\",color=:red); ts=first(solution.t):(mean(diff(solution.t))/2):last(solution.t); X̂=predict(p_trained,Xₙ[:,1],ts); pl_trajectory=plot(ts,transpose(X̂),xlabel=\"t\",ylabel=\"x(t),y(t)\",color=:red,label=[\"UDE Approximation\" nothing]); scatter!(solution.t,transpose(Xₙ),color=:black,label=[\"Measurements\" nothing]); Ȳ=[-p_[2]*(X̂[1,:].*X̂[2,:])\\';p_[3]*(X̂[1,:].*X̂[2,:])\\']; Ŷ=U(X̂,p_trained,st)[1]; pl_reconstruction=plot(ts,transpose(Ŷ),xlabel=\"t\",ylabel=\"U(x,y)\",color=:red,label=[\"UDE Approximation\" nothing]); plot!(ts,transpose(Ȳ),color=:black,label=[\"True Interaction\" nothing]); pl_reconstruction_error=plot(ts,norm.(eachcol(Ȳ-Ŷ)),yaxis=:log,xlabel=\"t\",ylabel=\"L2-Error\",label=nothing,color=:red); pl_missing=plot(pl_reconstruction,pl_reconstruction_error,layout=(2,1)); pl_overall=plot(pl_trajectory,pl_missing);```'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset:\n",
    "    print(message[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 335, 802\n",
      "mean / median: 568.5, 568.5\n",
      "p5 / p95: 381.7, 755.3\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 292, 755\n",
      "mean / median: 523.5, 523.5\n",
      "p5 / p95: 338.3, 708.7\n",
      "\n",
      "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 16385 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 16,385 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~1137 tokens that will be charged for during training\n",
      "By default, you'll train for 25 epochs on this dataset\n",
      "By default, you'll be charged for ~28425 tokens\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 16385\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
