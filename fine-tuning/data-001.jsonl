{"messages": [{"role": "system", "content": "SciMLGPT is a chatbot trained to generate Julia code for Scientific machine learning problems."}, {"role": "user", "content": "Solve the ODE for SIR model"}, {"role": "assistant", "content": "Here is the ode solver for the SIR model, ```using ComponentArrays, Lux, DiffEqFlux, OrdinaryDiffEq, Optimization, OptimizationOptimJL,OptimizationOptimisers, Random, Plots #u = [s(t), I(t), R(t)] function trueSirModel!(du, u, p, t) beta, gamma, N = p du[1] = -(beta * u[1] * u[2]) / N du[2] = ((beta * u[1] * u[2]) / N) - (gamma * u[2]) du[3] = gamma * u[2] end # Boundary conditions N = 1000 i0 = 1 r0 = 0 s0 = (N - i0 - r0) u0 = [s0, i0, r0] # constants beta = 0.3 gamma = 0.1 p = (beta, gamma, N)# time duration tspan = (0.0, 160.0) datasize = 160 tsteps = range(tspan[1], tspan[2]; length=datasize) # Solving the ODE solution trueOdeProblem = ODEProblem(trueSirModel!, u0, tspan, p) trueOdeData = Array(solve(trueOdeProblem, Tsit5(), saveat=tsteps))```"}]}
{"messages": [{"role": "system", "content": "SciMLGPT is a chatbot trained to generate Julia code for Scientific machine learning problems."}, {"role": "user", "content": "Implement the Neural ODE method for solving the SIR model "}, {"role": "assistant", "content": "Here is the neural ode implementation for the SIR model, ```using ComponentArrays, Lux, DiffEqFlux, OrdinaryDiffEq, Optimization, OptimizationOptimJL, OptimizationOptimisers, Random, Plots #u = [s(t), I(t), R(t)] function trueSirModel!(du, u, p, t) beta, gamma, N = p du[1] = -(beta * u[1] * u[2]) / N du[2] = ((beta * u[1] * u[2]) / N) - (gamma * u[2]) du[3] = gamma * u[2] end # Boundary conditions N = 1000 i0 = 1 r0 = 0 s0 = (N - i0 - r0) u0 = [s0, i0, r0] # constants beta = 0.3 gamma = 0.1 p = (beta, gamma, N) # time duration tspan = (0.0, 160.0) datasize = 160 tsteps = range(tspan[1], tspan[2]; length=datasize) # Solving the ODE solution trueOdeProblem = ODEProblem(trueSirModel!, u0, tspan, p) trueOdeData = Array(solve(trueOdeProblem, Tsit5(), saveat=tsteps)) # Defining the Nueral Network rng = Random.default_rng() # After multiple iteraations, the layer with 3x150 fit the true data very well. sirNN = Lux.Chain(Lux.Dense(3, 150, tanh), Lux.Dense(150, 150, tanh), Lux.Dense(150, 3)) p, st = Lux.setup(rng, sirNN) sirNNOde = NeuralODE(sirNN, tspan, Tsit5(), saveat=tsteps) # prediciton function that is determined for every iteration function prediction(p) Array(sirNNOde(u0, p, st)[1]) end # Loss represents the difference between the original data and the predicted output function loss(p) pred = prediction(p) loss = sum(abs2, trueOdeData .- pred) return loss, pred end # A Callback function to plot the output of the true dat and predicted output for suspectible, infected and recvered data points callback = function (p, l, pred; doplot=true) println(l) if doplot plt = scatter(tsteps, trueOdeData[1, :]; label=\"true suspectible\") scatter!(plt, tsteps, pred[1, :]; label=\"prediction suspectible\") iplt = scatter(tsteps, trueOdeData[2, :]; label=\"true infected\") scatter!(iplt, tsteps, pred[2, :]; label=\"prediction infected\") rplt = scatter(tsteps, trueOdeData[3, :]; label=\"true recovered\") scatter!(rplt, tsteps, pred[3, :]; label=\"prediction recovered\") display(plot(plt, iplt, rplt)) end return false end # Defining optimization techniques pinit = ComponentArray(p) adtype = Optimization.AutoZygote() optimizeFunction = Optimization.OptimizationFunction((x, p) -> loss(x), adtype) # Defining the problem to be optimize neuralProblem = Optimization.OptimizationProblem(optimizeFunction, pinit) # NN solver that iterates over 3000 using ADAM optimizer result = Optimization.solve(neuralProblem, Optimisers.Adam(0.001); callback=callback, maxiters=3000)```"}]}
{"messages": [{"role": "system", "content": "SciMLGPT is a chatbot trained to generate Julia code for Scientific machine learning problems."}, {"role": "user", "content": "Similarly provide the UDE implementation for the Lotka Voltera eqautions "}, {"role": "assistant", "content": "Here is the UDE implemenation for Lotka Voltera, ```using OrdinaryDiffEq, ModelingToolkit, SciMLSensitivity, DataDrivenSparse, Optimization, OptimizationOptimisers, OptimizationOptimJL, LinearAlgebra, Statistics, ComponentArrays, Lux, Zygote, Plots, StableRNGs; gr(); rng=StableRNG(1111); function lotka!(du,u,p,t) α,β,γ,δ=p; du[1]=α*u[1]-β*u[2]*u[1]; du[2]=γ*u[1]*u[2]-δ*u[2]; end; tspan=(0.0,15.0); u0=5.0f0*rand(rng,2); p_=[1.3,0.9,0.8,1.8]; prob=ODEProblem(lotka!,u0,tspan,p_); solution=solve(prob,Vern7(),abstol=1e-12,reltol=1e-12,saveat=0.25); X=Array(solution); t=solution.t; x̄=mean(X,dims=2); noise_magnitude=5e-3; Xₙ=X.+(noise_magnitude*x̄).*randn(rng,eltype(X),size(X)); plot(solution,alpha=0.75,color=:black,label=[\"True Data\" nothing]); scatter!(t,transpose(Xₙ),color=:red,label=[\"Noisy Data\" nothing]); rbf(x)=exp.(-(x.^2)); const U=Lux.Chain(Lux.Dense(2,5,rbf),Lux.Dense(5,5,rbf),Lux.Dense(5,5,rbf),Lux.Dense(5,2)); p,st=Lux.setup(rng,U); const _st=st; function ude_dynamics!(du,u,p,t,p_true) û=U(u,p,_st)[1]; du[1]=p_true[1]*u[1]+û[1]; du[2]=-p_true[4]*u[2]+û[2]; end; nn_dynamics!(du,u,p,t)=ude_dynamics!(du,u,p,t,p_); prob_nn=ODEProblem(nn_dynamics!,Xₙ[:,1],tspan,p); function predict(θ,X=Xₙ[:,1],T=t) _prob=remake(prob_nn,u0=X,tspan=(T[1],T[end]),p=θ); Array(solve(_prob,Vern7(),saveat=T,abstol=1e-6,reltol=1e-6,sensealg=QuadratureAdjoint(autojacvec=ReverseDiffVJP(true)))); end; function loss(θ) X̂=predict(θ); mean(abs2,Xₙ.-X̂); end; losses=Float64[]; callback=function(p,l) push!(losses,l); if length(losses)%50==0 println(\"Current loss after $(length(losses)) iterations: $(losses[end])\"); end; return false; end; adtype=Optimization.AutoZygote(); optf=Optimization.OptimizationFunction((x,p)->loss(x),adtype); optprob=Optimization.OptimizationProblem(optf,ComponentVector{Float64}(p)); res1=Optimization.solve(optprob,ADAM(),callback=callback,maxiters=5000); println(\"Training loss after $(length(losses)) iterations: $(losses[end])\"); optprob2=Optimization.OptimizationProblem(optf,res1.u); res2=Optimization.solve(optprob2,Optim.LBFGS(),callback=callback,maxiters=1000); println(\"Final training loss after $(length(losses)) iterations: $(losses[end])\"); p_trained=res2.u; pl_losses=plot(1:5000,losses[1:5000],yaxis=:log10,xaxis=:log10,xlabel=\"Iterations\",ylabel=\"Loss\",label=\"ADAM\",color=:blue); plot!(5001:length(losses),losses[5001:end],yaxis=:log10,xaxis=:log10,xlabel=\"Iterations\",ylabel=\"Loss\",label=\"BFGS\",color=:red); ts=first(solution.t):(mean(diff(solution.t))/2):last(solution.t); X̂=predict(p_trained,Xₙ[:,1],ts); pl_trajectory=plot(ts,transpose(X̂),xlabel=\"t\",ylabel=\"x(t),y(t)\",color=:red,label=[\"UDE Approximation\" nothing]); scatter!(solution.t,transpose(Xₙ),color=:black,label=[\"Measurements\" nothing]); Ȳ=[-p_[2]*(X̂[1,:].*X̂[2,:])';p_[3]*(X̂[1,:].*X̂[2,:])']; Ŷ=U(X̂,p_trained,st)[1]; pl_reconstruction=plot(ts,transpose(Ŷ),xlabel=\"t\",ylabel=\"U(x,y)\",color=:red,label=[\"UDE Approximation\" nothing]); plot!(ts,transpose(Ȳ),color=:black,label=[\"True Interaction\" nothing]); pl_reconstruction_error=plot(ts,norm.(eachcol(Ȳ-Ŷ)),yaxis=:log,xlabel=\"t\",ylabel=\"L2-Error\",label=nothing,color=:red); pl_missing=plot(pl_reconstruction,pl_reconstruction_error,layout=(2,1)); pl_overall=plot(pl_trajectory,pl_missing);```"}]}
{"messages": [{"role": "system", "content": "SciMLGPT is a chatbot trained to generate Julia code for Scientific machine learning problems."}, {"role": "user", "content": "Provide the Neural ODE implementation for modelling the Black hole dynamics"} , {"role": "assistant", "content": "# SciML Tools using OrdinaryDiffEq, ModelingToolkit, DataDrivenDiffEq, SciMLSensitivity, DataDrivenSparse using Optimization, OptimizationOptimisers, OptimizationOptimJL # Standard Libraries using LinearAlgebra, Statistics # External Libraries using ComponentArrays, Lux, Zygote, Plots, StableRNGs, DataFrames, CSV, LineSearches gr() # Set a random seed for reproducible behaviour rng = StableRNG(1111) mass_ratio = 0.0 # test particle u0 = Float64[pi, 0.0] # initial conditions datasize = 250 tspan = (0.0f0, 6.0f4) # timespace for GW waveform tsteps = range(tspan[1], tspan[2], length = datasize) # time at each timestep dt_data = tsteps[2] - tsteps[1] dt = 100.0 model_params = [100.0, 1.0, 0.5]; # p, M, e prob = ODEProblem(RelativisticOrbitModel, u0, tspan, model_params) soln = Array(solve(prob, RK4(), saveat = tsteps, dt = dt, adaptive = false)) waveform = compute_waveform(dt_data, soln, mass_ratio, model_params)[1] plt = plot(tsteps, waveform, markershape = :circle, markeralpha = 0.25, linewidth = 2, alpha = 0.5, label = \"waveform data\", xlabel = \"Time\", ylabel = \"Waveform\") NN = Lux.Chain((x) -> cos.(x), Lux.Dense(1, 32, cos), Lux.Dense(32, 32, cos), Lux.Dense(32, 2)) p, st = Lux.setup(rng, NN) NN_params = ComponentArray{Float64}(p) function ODE_model(u, NN_params, t) du = AbstractNNOrbitModel(u, model_params, t, NN = NN, NN_params = NN_params) return du end prob_nn = ODEProblem(ODE_model, u0, tspan, NN_params) soln_nn = Array(solve( prob_nn, RK4(), u0 = u0, p = NN_params, saveat = tsteps, dt = dt, adaptive = false)) waveform_nn = compute_waveform(dt_data, soln_nn, mass_ratio, model_params)[1] plot!(plt, tsteps, waveform_nn, markershape = :circle, markeralpha = 0.25, linewidth = 2, alpha = 0.5, label = \"waveform NN\") display(plt) function loss(NN_params) first_obs_to_use_for_training = 1 last_obs_to_use_for_training = length(waveform) obs_to_use_for_training = first_obs_to_use_for_training:last_obs_to_use_for_training pred = Array(solve( prob_nn, RK4(), u0 = u0, p = NN_params, saveat = tsteps, dt = dt, adaptive = false)) pred_waveform = compute_waveform(dt_data, pred, mass_ratio, model_params)[1] loss = ( sum(abs2, view(waveform,obs_to_use_for_training) .- view(pred_waveform,obs_to_use_for_training) ) ) return loss end losses = [] callback(state, l; doplot = true) = begin push!(losses, l) #= Disable plotting as it trains since in docs display(l) waveform = compute_waveform(dt_data, soln, mass_ratio, model_params)[1] # plot current prediction against data plt = plot(tsteps, waveform, markershape=:circle, markeralpha = 0.25, linewidth = 2, alpha = 0.5, label=\"wform data (h22)\", legend=:topleft) plot!(plt, tsteps, pred_waveform, markershape=:circle, markeralpha = 0.25, linewidth = 2, alpha = 0.5, label = \"wform NN\") if doplot display(plot(plt)) end # Tell sciml_train to not halt the optimization. If return true, then # optimization stops. =# return false end NN_params = NN_params .* 0 + Float64(1e-4) * randn(StableRNG(2031), eltype(NN_params), size(NN_params)) adtype = Optimization.AutoZygote() optf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype) optprob = Optimization.OptimizationProblem(optf, ComponentVector{Float64}(NN_params)) res1 = Optimization.solve( optprob, OptimizationOptimisers.Adam(0.001f0), callback = callback, maxiters = 100) optprob = Optimization.OptimizationProblem(optf, res1.u) res2 = Optimization.solve( optprob, BFGS(initial_stepnorm = 0.01, linesearch = LineSearches.BackTracking()), callback = callback, maxiters = 20) reference_solution = solve(remake(prob, p = model_params, saveat = tsteps, tspan = tspan), RK4(), dt = dt, adaptive = false) optimized_solution = solve( remake(prob_nn, p = res2.minimizer, saveat = tsteps, tspan = tspan), RK4(), dt = dt, adaptive = false) Newtonian_prob = ODEProblem(NewtonianOrbitModel, u0, tspan, model_params) Newtonian_solution = solve( remake(Newtonian_prob, p = model_params, saveat = tsteps, tspan = tspan), RK4(), dt = dt, adaptive = false) true_orbit = soln2orbit(reference_solution, model_params) pred_orbit = soln2orbit(optimized_solution, model_params) Newt_orbit = soln2orbit(Newtonian_solution, model_params) true_waveform = compute_waveform(dt_data, reference_solution, mass_ratio, model_params)[1] pred_waveform = compute_waveform(dt_data, optimized_solution, mass_ratio, model_params)[1] Newt_waveform = compute_waveform(dt_data, Newtonian_solution, mass_ratio, model_params)[1] true_orbit = soln2orbit(reference_solution, model_params) pred_orbit = soln2orbit(optimized_solution, model_params) Newt_orbit = soln2orbit(Newtonian_solution, model_params) plt = plot(true_orbit[1, :], true_orbit[2, :], linewidth = 2, label = \"truth\") plot!(plt, pred_orbit[1, :], pred_orbit[2, :], linestyle = :dash, linewidth = 2, label = \"prediction\") plot!(plt, Newt_orbit[1, :], Newt_orbit[2, :], linewidth = 2, label = \"Newtonian\") plt = plot(tsteps, true_waveform, linewidth = 2, label = \"truth\", xlabel = \"Time\", ylabel = \"Waveform\") plot!(plt, tsteps, pred_waveform, linestyle = :dash, linewidth = 2, label = \"prediction\") plot!(plt, tsteps, Newt_waveform, linewidth = 2, label = \"Newtonian\") factor = 5 extended_tspan = (tspan[1], factor * tspan[2]) extended_tsteps = range(tspan[1], factor * tspan[2], length = factor * datasize) reference_solution = solve( remake(prob, p = model_params, saveat = extended_tsteps, tspan = extended_tspan), RK4(), dt = dt, adaptive = false) optimized_solution = solve( remake(prob_nn, p = res2.minimizer, saveat = extended_tsteps, tspan = extended_tspan), RK4(), dt = dt, adaptive = false) Newtonian_prob = ODEProblem(NewtonianOrbitModel, u0, tspan, model_params) Newtonian_solution = solve( remake( Newtonian_prob, p = model_params, saveat = extended_tsteps, tspan = extended_tspan), RK4(), dt = dt, adaptive = false) true_orbit = soln2orbit(reference_solution, model_params) pred_orbit = soln2orbit(optimized_solution, model_params) Newt_orbit = soln2orbit(Newtonian_solution, model_params) plt = plot(true_orbit[1, :], true_orbit[2, :], linewidth = 2, label = \"truth\") plot!(plt, pred_orbit[1, :], pred_orbit[2, :], linestyle = :dash, linewidth = 2, label = \"prediction\") plot!(plt, Newt_orbit[1, :], Newt_orbit[2, :], linewidth = 2, label = \"Newtonian\") true_waveform = compute_waveform(dt_data, reference_solution, mass_ratio, model_params)[1] pred_waveform = compute_waveform(dt_data, optimized_solution, mass_ratio, model_params)[1] Newt_waveform = compute_waveform(dt_data, Newtonian_solution, mass_ratio, model_params)[1] plt = plot(extended_tsteps, true_waveform, linewidth = 2, label = \"truth\", xlabel = \"Time\", ylabel = \"Waveform\") plot!(plt, extended_tsteps, pred_waveform, linestyle = :dash, linewidth = 2, label = \"prediction\")"}]}
{"messages": [{"role": "system", "content": "SciMLGPT is a chatbot trained to generate Julia code for Scientific machine learning problems."}, {"role": "user", "content": "Model the uncertaininity of Uncertainty quantified discovery of chemical reaction using SciML"} , {"role": "assistant", "content": "using Flux, Random, Plots; using DiffEqFlux, DifferentialEquations, LinearAlgebra, Statistics, BSON: @save, @load; Random.seed!(1234); is_restart = false; p_cutoff = 0.0; n_epoch = 60000; n_plot = 100; opt = ADAMW(0.001, (0.9, 0.999), 1f-8); datasize = 75; tstep = 0.4; n_exp_train = 100; n_exp_test = 10; n_exp = n_exp_train + n_exp_test; noise = 0; ns = 5; nr = 4; k = Float32[0.1, 0.2, 0.13, 0.3]; alg = Tsit5(); atol = 1e-5; rtol = 1e-2; maxiters = 1000000; lb = 1f-5; ub = 1f1; function trueODEfunc(dydt, y, k, t); dydt[1] = -2 * k[1] * y[1]^2 - k[2] * y[1]; dydt[2] = k[1] * y[1]^2 - k[4] * y[2] * y[4]; dydt[3] = k[2] * y[1] - k[3] * y[3]; dydt[4] = k[3] * y[3] - k[4] * y[2] * y[4]; dydt[5] = k[4] * y[2] * y[4]; end; u0_list = rand(Float32, (n_exp, ns)); u0_list[:, 1:2] .+= 0.2; u0_list[:, 3:end] .= 0f0; tspan = Float32[0.0, datasize * tstep]; tsteps = range(tspan[1], tspan[2], length=datasize); ode_data_list = zeros(Float32, (n_exp, ns, datasize)); std_list = []; function max_min(ode_data); return maximum(ode_data, dims=2) .- minimum(ode_data, dims=2) .+ lb; end; for i in 1:n_exp; u0 = u0_list[i, :]; prob_trueode = ODEProblem(trueODEfunc, u0, tspan, k); ode_data = Array(solve(prob_trueode, alg, saveat=tsteps)); ode_data += randn(size(ode_data)) .* ode_data .* noise; ode_data_list[i, :, :] = ode_data; push!(std_list, max_min(ode_data)); end; y_std = maximum(hcat(std_list...), dims=2); u0_list = u0_list'; ode_data_list = permutedims(ode_data_list, [2, 3, 1]); data = Flux.DataLoader((u0_list, ode_data_list), batchsize=10); dudt = Chain(Dense(5, 50, tanh), Dense(50, 50, tanh), Dense(50, 5)); n_ode = NeuralODE(dudt, tspan, Tsit5(), saveat=tsteps); function loss_n_ode(u0, y, n_ode); result = n_ode(u0); result = permutedims(result, [1, 3, 2]); return mae(y, result); end; opt_state = Flux.setup(Adam(0.001), n_ode); loss_history = Float32[]; for epoch in 1:1000; Flux.train!(n_ode, data, opt_state) do n_ode, x, y; err = loss_n_ode(x, y, n_ode); ChainRules.ignore_derivatives() do; push!(loss_history, err); end; @show err; return err; end; end; prediction = n_ode(u0_list[:, 1]); plot(prediction[1, :]); plot!(ode_data_list[1, :, 1]); pred_ode_data = zeros(Float64, (n_exp_train, ns, datasize)); extrap_ode_data = zeros(Float64, (n_exp_train, ns, datasize)); for i in 1:n_exp_train; u0_i = u0_list[:, i]; pred = Array(n_ode(u0_i)); pred_ode_data[i, :, :] = pred; u0_n = [pred[1, end], pred[2, end], pred[3, end], pred[4, end], pred[5, end]]; extra_pred = Array(n_ode(u0_n)); extrap_ode_data[i, :, :] = extra_pred; end; datasize = 100; tspan = Float32[0.0, datasize * tstep]; tsteps = range(tspan[1], tspan[2], length=datasize); ode_data_list = zeros(Float32, (n_exp_train, ns, datasize)); for i in 1:n_exp_train; u0 = u0_list[:, i]; prob_trueode = ODEProblem(trueODEfunc, u0, tspan, k); ode_data = Array(solve(prob_trueode, alg, saveat=tsteps)); ode_data_list[i, :, :] = ode_data; end; JLD2.@save \"simp_rxn_nODE_100_truthv4\" ode_data_list;"}]}
{"messages": [{"role": "system", "content": "SciMLGPT is a chatbot trained to generate Julia code for Scientific machine learning problems."}, {"role": "user", "content": "Using UDEs model the non newtonian fluids"} , {"role": "assistant", "content": "using Flux, Random, Plots; using DiffEqFlux, DifferentialEquations, LinearAlgebra, Statistics, BSON: @save, @load; Random.seed!(1234); is_restart = false; p_cutoff = 0.0; n_epoch = 60000; n_plot = 100; opt = ADAMW(0.001, (0.9, 0.999), 1f-8); datasize = 75; tstep = 0.4; n_exp_train = 100; n_exp_test = 10; n_exp = n_exp_train + n_exp_test; noise = 0; ns = 5; nr = 4; k = Float32[0.1, 0.2, 0.13, 0.3]; alg = Tsit5(); atol = 1e-5; rtol = 1e-2; maxiters = 1000000; lb = 1f-5; ub = 1f1; function trueODEfunc(dydt, y, k, t); dydt[1] = -2 * k[1] * y[1]^2 - k[2] * y[1]; dydt[2] = k[1] * y[1]^2 - k[4] * y[2] * y[4]; dydt[3] = k[2] * y[1] - k[3] * y[3]; dydt[4] = k[3] * y[3] - k[4] * y[2] * y[4]; dydt[5] = k[4] * y[2] * y[4]; end; u0_list = rand(Float32, (n_exp, ns)); u0_list[:, 1:2] .+= 0.2; u0_list[:, 3:end] .= 0f0; tspan = Float32[0.0, datasize * tstep]; tsteps = range(tspan[1], tspan[2], length=datasize); ode_data_list = zeros(Float32, (n_exp, ns, datasize)); std_list = []; function max_min(ode_data); return maximum(ode_data, dims=2) .- minimum(ode_data, dims=2) .+ lb; end; for i in 1:n_exp; u0 = u0_list[i, :]; prob_trueode = ODEProblem(trueODEfunc, u0, tspan, k); ode_data = Array(solve(prob_trueode, alg, saveat=tsteps)); ode_data += randn(size(ode_data)) .* ode_data .* noise; ode_data_list[i, :, :] = ode_data; push!(std_list, max_min(ode_data)); end; y_std = maximum(hcat(std_list...), dims=2); u0_list = u0_list'; ode_data_list = permutedims(ode_data_list, [2, 3, 1]); data = Flux.DataLoader((u0_list, ode_data_list), batchsize=10); dudt = Chain(Dense(5, 50, tanh), Dense(50, 50, tanh), Dense(50, 5)); n_ode = NeuralODE(dudt, tspan, Tsit5(), saveat=tsteps); function loss_n_ode(u0, y, n_ode); result = n_ode(u0); result = permutedims(result, [1, 3, 2]); return mae(y, result); end; opt_state = Flux.setup(Adam(0.001), n_ode); loss_history = Float32[]; for epoch in 1:1000; Flux.train!(n_ode, data, opt_state) do n_ode, x, y; err = loss_n_ode(x, y, n_ode); ChainRules.ignore_derivatives() do; push!(loss_history, err); end; @show err; return err; end; end; prediction = n_ode(u0_list[:, 1]); plot(prediction[1, :]); plot!(ode_data_list[1, :, 1]); pred_ode_data = zeros(Float64, (n_exp_train, ns, datasize)); extrap_ode_data = zeros(Float64, (n_exp_train, ns, datasize)); for i in 1:n_exp_train; u0_i = u0_list[:, i]; pred = Array(n_ode(u0_i)); pred_ode_data[i, :, :] = pred; u0_n = [pred[1, end], pred[2, end], pred[3, end], pred[4, end], pred[5, end]]; extra_pred = Array(n_ode(u0_n)); extrap_ode_data[i, :, :] = extra_pred; end; datasize = 100; tspan = Float32[0.0, datasize * tstep]; tsteps = range(tspan[1], tspan[2], length=datasize); ode_data_list = zeros(Float32, (n_exp_train, ns, datasize)); for i in 1:n_exp_train; u0 = u0_list[:, i]; prob_trueode = ODEProblem(trueODEfunc, u0, tspan, k); ode_data = Array(solve(prob_trueode, alg, saveat=tsteps)); ode_data_list[i, :, :] = ode_data; end; JLD2.@save \"simp_rxn_nODE_100_truthv4\" ode_data_list;"}]}
{"messages": [{"role": "system", "content": "SciMLGPT is a chatbot trained to generate Julia code for Scientific machine learning problems."}, {"role": "user", "content": "Give the UDE implementation of Hamilton Jacobi Bellman Equation"} , {"role": "assistant", "content": "cd(@__DIR__); using Pkg; Pkg.activate(\".\"); Pkg.instantiate(); using Flux, StochasticDiffEq, LinearAlgebra, Statistics, Test, NeuralNetDiffEq; using Random; Random.seed!(0); d = 100; x0 = fill(0.0f0,d); tspan = (0.0f0, 1.0f0); m = 100; λ = 1.0f0; g(X) = log(0.5f0 + 0.5f0*sum(X.^2)); f(X,u,σᵀ∇u,p,t) = -λ*sum(σᵀ∇u.^2); μ(X,p,t) = zero(X); σ(X,p,t) = Diagonal(sqrt(2.0f0)*ones(Float32,d)); prob = TerminalPDEProblem(g, f, μ, σ, x0, tspan); hls = 10 + d; opt = Flux.ADAM(0.03); u0 = Flux.Chain(Dense(d,hls,relu), Dense(hls,hls,relu), Dense(hls,1)); σᵀ∇u = Flux.Chain(Dense(d+1,hls,relu), Dense(hls,hls,relu), Dense(hls,hls,relu), Dense(hls,d)); pdealg = NNPDENS(u0, σᵀ∇u, opt=opt); @time ans = solve(prob, pdealg, verbose=true, maxiters=500, trajectories=m, alg=LambaEM(), pabstol = 1f-2, reltol=1e-4, abstol=1e-4); T = tspan[2]; MC = 10^5; W() = randn(d,1); u_analytical(x, t) = -(1/λ)*log(mean(exp(-λ*g(x .+ sqrt(2.0)*abs.(T-t).*W())) for _ = 1:MC)); analytical_ans = u_analytical(x0, tspan[1]); error_l2 = sqrt((ans - analytical_ans)^2/ans^2); println(\"Hamilton Jacobi Bellman Equation\"); println(\"error_l2 = \", error_l2, \"n\"); @test error_l2 < 0.2"}]}
{"messages": [{"role": "system", "content": "SciMLGPT is a chatbot trained to generate Julia code for Scientific machine learning problems."}, {"role": "user", "content": "Give the UDE implementation of Hamilton Jacobi Bellman Equation"} , {"role": "assistant", "content": "cd(@__DIR__); using Pkg; Pkg.activate(\".\"); Pkg.instantiate(); using Flux, StochasticDiffEq, LinearAlgebra, Statistics, Test, NeuralNetDiffEq; using Random; Random.seed!(0); d = 100; x0 = fill(0.0f0,d); tspan = (0.0f0, 1.0f0); m = 100; λ = 1.0f0; g(X) = log(0.5f0 + 0.5f0*sum(X.^2)); f(X,u,σᵀ∇u,p,t) = -λ*sum(σᵀ∇u.^2); μ(X,p,t) = zero(X); σ(X,p,t) = Diagonal(sqrt(2.0f0)*ones(Float32,d)); prob = TerminalPDEProblem(g, f, μ, σ, x0, tspan); hls = 10 + d; opt = Flux.ADAM(0.03); u0 = Flux.Chain(Dense(d,hls,relu), Dense(hls,hls,relu), Dense(hls,1)); σᵀ∇u = Flux.Chain(Dense(d+1,hls,relu), Dense(hls,hls,relu), Dense(hls,hls,relu), Dense(hls,d)); pdealg = NNPDENS(u0, σᵀ∇u, opt=opt); @time ans = solve(prob, pdealg, verbose=true, maxiters=500, trajectories=m, alg=LambaEM(), pabstol = 1f-2, reltol=1e-4, abstol=1e-4); T = tspan[2]; MC = 10^5; W() = randn(d,1); u_analytical(x, t) = -(1/λ)*log(mean(exp(-λ*g(x .+ sqrt(2.0)*abs.(T-t).*W())) for _ = 1:MC)); analytical_ans = u_analytical(x0, tspan[1]); error_l2 = sqrt((ans - analytical_ans)^2/ans^2); println(\"Hamilton Jacobi Bellman Equation\"); println(\"error_l2 = \", error_l2, \"n\"); @test error_l2 < 0.2"}]}
{"messages": [{"role": "system", "content": "SciMLGPT is a chatbot trained to generate Julia code for Scientific machine learning problems."}, {"role": "user", "content": "Solve the simple PDE solver for Schrodinger equation"} , {"role": "assistant", "content": "using OrdinaryDiffEq, ModelingToolkit, MethodOfLines, DomainSets; @parameters t, x; @variables psi(..); Dt = Differential(t); Dxx = Differential(x)^2; xmin = 0; xmax = 1; V(x) = 0.0; eq = [im * Dt(psi(t, x)) ~ Dxx(psi(t, x)) + V(x) * psi(t, x)]; psi0 = x -> sin(2pi * x); bcs = [psi(0, x) ~ psi0(x), psi(t, xmin) ~ 0, psi(t, xmax) ~ 0]; domains = [t ∈ Interval(0, 1), x ∈ Interval(xmin, xmax)]; @named sys = PDESystem(eq, bcs, domains, [t, x], [psi(t, x)]); disc = MOLFiniteDifference([x => 100], t); prob = discretize(sys, disc); sol = solve(prob, TRBDF2(), saveat=0.01); discx = sol[x]; disct = sol[t]; sol[psi(t, x)]; using Plots; discPsi = sol[psi(t, x)]; anim = @animate for i in 1:length(disct); u = discPsi[i, :]; plot(discx, [real.(u), imag.(u)], ylim=(-1.5, 1.5), title=\"t = $(disct[i])\", xlabel=\"x\", ylabel=\"psi(t,x)\", label=[\"re(psi)\" \"im(psi)\"], legend=:topleft); end; gif(anim, \"schroedinger.gif\", fps=10)"}]}
{"messages": [{"role": "system", "content": "SciMLGPT is a chatbot trained to generate Julia code for Scientific machine learning problems."}, {"role": "user", "content": "Solve the PDE equation system for 1D wave equation using Neural ODE"} , {"role": "assistant", "content": "using NeuralPDE, Lux, Optimization, OptimizationOptimJL; using ModelingToolkit: Interval; @parameters t, x; @variables u(..); @derivatives Dxx'' ~ x; @derivatives Dtt'' ~ t; @derivatives Dt' ~ t; C = 1; eq = Dtt(u(t, x)) ~ C^2 * Dxx(u(t, x)); bcs = [u(t, 0) ~ 0.0, u(t, 1) ~ 0.0, u(0, x) ~ x * (1.0 - x), Dt(u(0, x)) ~ 0.0]; domains = [t ∈ Interval(0.0, 1.0), x ∈ Interval(0.0, 1.0)]; dx = 0.1; chain = Lux.Chain(Dense(2, 16, Lux.σ), Dense(16, 16, Lux.σ), Dense(16, 1)); discretization = PhysicsInformedNN(chain, GridTraining(dx)); @named pde_system = PDESystem(eq, bcs, domains, [t, x], [u(t, x)]); prob = discretize(pde_system, discretization); callback = function (_, l); println(\"Loss is: $l\"); return false; end; opt = OptimizationOptimJL.BFGS(); res = Optimization.solve(prob, opt; callback=callback, maxiters=1500); phi = discretization.phi; using Plots; ts, xs = [infimum(d.domain):dx:supremum(d.domain) for d in domains]; function analytic_sol_func(t, x); sum([(8 / (k^3 * pi^3)) * sin(k * pi * x) * cos(C * k * pi * t) for k in 1:2:50000]); end; u_predict = reshape([first(phi([t, x], res.u)) for t in ts for x in xs], (length(ts), length(xs))); u_real = reshape([analytic_sol_func(t, x) for t in ts for x in xs], (length(ts), length(xs))); p1 = plot(ts, xs, u_real, linetype=:contourf, title=\"analytic\"); p2 = plot(ts, xs, u_predict, linetype=:contourf, title=\"predict\"); plot(p1, p2)"}]}